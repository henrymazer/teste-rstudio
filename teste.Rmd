---
title: "Teste"
author: "Henry Mazer"
date: "2023-06-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Mulheres no mercado de trabalho

- Mudanças nas profissões que elas ocupam
- Avaliar essa diferença no tempo
- Imagem que salvei do googgle keep da aula: [link pro keep](https://keep.google.com/u/0/#NOTE/11r1RVFeXechn6-WYsxqIV_Q9DTySIa2uRAtpyphZafE9_rGhx45SCr77OTm4kHE)

# Tirado do curso John Hopkins

Types of data science questions
In this lesson, we’re going to be a little more conceptual and look at some of the types of analyses data scientists employ to answer questions in data science.

The main divisions of data science questions
There are, broadly speaking, six categories in which data analyses fall. In the approximate order of difficulty, they are:

Descriptive
Exploratory
Inferential
Predictive
Causal
Mechanistic
Let’s explore the goals of each of these types and look at some examples of each analysis!

1. Descriptive analysis
The goal of descriptive analysis is to describe or summarize a set of data. Whenever you get a new dataset to examine, this is usually the first kind of analysis you will perform. Descriptive analysis will generate simple summaries about the samples and their measurements. You may be familiar with common descriptive statistics: measures of central tendency (eg: mean, median, mode) or measures of variability (eg: range, standard deviations or variance).

This type of analysis is aimed at summarizing your sample – not for generalizing the results of the analysis to a larger population or trying to make conclusions. Description of data is separated from making interpretations; generalizations and interpretations require additional statistical steps.

Some examples of purely descriptive analysis can be seen in censuses. Here, the government collects a series of measurements on all of the country’s citizens, which can then be summarized. Here, you are being shown the age distribution in the US, stratified by sex. The goal of this is just to describe the distribution. There is no inferences about what this means or predictions on how the data might trend in the future. It is just to show you a summary of the data collected.

A population pyramid describing the population distribution in the US
A population pyramid describing the population distribution in the US

2. Exploratory analysis
The goal of exploratory analysis is to examine or explore the data and find relationships that weren’t previously known. Exploratory analyses explore how different measures might be related to each other but do not confirm that relationship as causitive. You’ve probably heard the phrase “Correlation does not imply causation” and exploratory analyses lie at the root of this saying. Just because you observe a relationship between two variables during exploratory analysis, it does not mean that one necessarily causes the other.

Because of this, exploratory analyses, while useful for discovering new connections, should not be the final say in answering a question! It can allow you to formulate hypotheses and drive the design of future studies and data collection, but exploratory analysis alone should never be used as the final say on why or how data might be related to each other.

Going back to the census example from above, rather than just summarizing the data points within a single variable, we can look at how two or more variables might be related to each other. In the plot below, we can see the percent of the workforce that is made up of women in various sectors and how that has changed between 2000 and 2016. Exploring this data, we can see quite a few relationships. Looking just at the top row of the data, we can see that women make up a vast majority of nurses and that it has slightly decreased in 16 years. While these are interesting relationships to note, the causes of these relationships is not apparent from this analysis. All exploratory analysis can tell us is that a relationship exists, not the cause.

Exploring the relationships between the percentage of women in the workforce in various sectors between 2000 and 2016
Exploring the relationships between the percentage of women in the workforce in various sectors between 2000 and 2016

3. Inferential analysis
The goal of inferential analyses is to use a relatively small sample of data to infer or say something about the population at large. Inferential analysis is commonly the goal of statistical modelling, where you have a small amount of information to extrapolate and generalize that information to a larger group.

Inferential analysis typically involves using the data you have to estimate that value in the population and then give a measure of your uncertainty about your estimate. Since you are moving from a small amount of data and trying to generalize to a larger population, your ability to accurately infer information about the larger population depends heavily on your sampling scheme - if the data you collect is not from a representative sample of the population, the generalizations you infer won’t be accurate for the population.

Unlike in our previous examples, we shouldn’t be using census data in inferential analysis - a census already collects information on (functionally) the entire population, there is nobody left to infer to; and inferring data from the US census to another country would not be a good idea because the US isn’t necessarily representative of another country that we are trying to infer knowledge about. Instead, a better example of inferential analysis is a study in which a subset of the US population was assayed for their life expectancy given the level of air pollution they experienced. This study uses the data they collected from a sample of the US population to infer how air pollution might be impacting life expectancy in the entire US.

4. Predictive analysis
The goal of predictive analysis is to use current data to make predictions about future data. Essentially, you are using current and historical data to find patterns and predict the likelihood of future outcomes.

Like in inferential analysis, your accuracy in predictions is dependent on measuring the right variables. If you aren’t measuring the right variables to predict an outcome, your predictions aren’t going to be accurate. Additionally, there are many ways to build up prediction models with some being better or worse for specific cases, but in general, having more data and a simple model generally performs well at predicting future outcomes.

All this being said, much like in exploratory analysis, just because one variable may predict another, it does not mean that one causes the other; you are just capitalizing on this observed relationship to predict the second variable.

A common saying is that prediction is hard, especially about the future. There aren’t easy ways to gauge how well you are going to predict an event until that event has come to pass; so evaluating different approaches or models is a challenge.

We spend a lot of time trying to predict things - the upcoming weather, the outcomes of sports events, and in the example we’ll explore here, the outcomes of elections. We’ve previously mentioned Nate Silver of FiveThirtyEight, where they try and predict the outcomes of U.S. elections (and sports matches, too!). Using historical polling data and trends and current polling, FiveThirtyEight builds models to predict the outcomes in the next US Presidential vote - and has been fairly accurate at doing so! FiveThirtyEight’s models accurately predicted the 2008 and 2012 elections and was widely considered an outlier in the 2016 US elections, as it was one of the few models to suggest Donald Trump at having a chance of winning.

FiveThirtyEight’s predictions over time for the winner of the US 2016 election
FiveThirtyEight’s predictions over time for the winner of the US 2016 election

5. Causal analysis
The caveat to a lot of the analyses we’ve looked at so far is that we can only see correlations and can’t get at the cause of the relationships we observe. Causal analysis fills that gap; the goal of causal analysis is to see what happens to one variable when we manipulate another variable - looking at the cause and effect of a relationship.

Generally, causal analyses are fairly complicated to do with observed data alone; there will always be questions as to whether it is correlation driving your conclusions or that the assumptions underlying your analysis are valid. More often, causal analyses are applied to the results of randomized studies that were designed to identify causation. Causal analysis is often considered the gold standard in data analysis, and is seen frequently in scientific studies where scientists are trying to identify the cause of a phenomenon, but often getting appropriate data for doing a causal analysis is a challenge.

One thing to note about causal analysis is that the data is usually analysed in aggregate and observed relationships are usually average effects; so, while on average giving a certain population a drug may alleviate the symptoms of a disease, this causal relationship may not hold true for every single affected individual.

As we’ve said, many scientific studies allow for causal analyses. Randomized control trials for drugs are a prime example of this. For example, one randomized control trial examined the effects of a new drug on treating infants with spinal muscular atrophy. Comparing a sample of infants receiving the drug versus a sample receiving a mock control, they measure various clinical outcomes in the babies and look at how the drug affects the outcomes.

6. Mechanistic analysis
Mechanistic analyses are not nearly as commonly used as the previous analyses - the goal of mechanistic analysis is to understand the exact changes in variables that lead to exact changes in other variables. These analyses are exceedingly hard to use to infer much, except in simple situations or in those that are nicely modeled by deterministic equations. Given this description, it might be clear to see how mechanistic analyses are most commonly applied to physical or engineering sciences; biological sciences, for example, are far too noisy of data sets to use mechanistic analysis. Often, when these analyses are applied, the only noise in the data is measurement error, which can be accounted for.

You can generally find examples of mechanistic analysis in material science experiments. Here, we have a study on biocomposites (essentially, making biodegradable plastics) that was examining how biocarbon particle size, functional polymer type and concentration affected mechanical properties of the resulting “plastic.” They are able to do mechanistic analyses through a careful balance of controlling and manipulating variables with very accurate measures of both those variables and the desired outcome.

Summary
In this lesson we’ve covered the various types of data analysis, their goals, and looked at a few examples of each to demonstrate what each analysis is capable of (and importantly, what it is not).

Principles of experimental design
There are a lot of concepts and terms inherent to experimental design. Let’s go over some of these now!

Independent variable (AKA factor): The variable that the experimenter manipulates; it does not depend on other variables being measured. Often displayed on the x-axis.

Dependent variable: The variable that is expected to change as a result of changes in the independent variable. Often displayed on the y-axis, so that changes in X, the independent variable, effect changes in Y.

So when you are designing an experiment, you have to decide what variables you will measure, and which you will manipulate to effect changes in other measured variables. Additionally, you must develop your hypothesis, essentially an educated guess as to the relationship between your variables and the outcome of your experiment.

How hypotheses, independent, and dependent variables are related to each other
How hypotheses, independent, and dependent variables are related to each other

Let’s do an example experiment now! Let’s say for example that I have a hypothesis that as shoe size increases, literacy also increases. In this case, designing my experiment, I would choose a measure of literacy (eg: reading fluency) as my variable that depends on an individual’s shoe size.

My experimental set-up: I hypothesize that literacy level depends on shoe size
My experimental set-up: I hypothesize that literacy level depends on shoe size

To answer this question, I will design an experiment in which I measure the shoe size and literacy level of 100 individuals. Sample size is the number of experimental subjects you will include in your experiment. There are ways to pick an optimal sample size, that you will cover in later courses. Before I collect my data though, I need to consider if there are problems with this experiment that might cause an erroneous result. In this case, my experiment may be fatally flawed by a confounder.

Confounder: An extraneous variable that may affect the relationship between the dependent and independent variables.

In our example, since age affects foot size and literacy is affected by age, if we see any relationship between shoe size and literacy, the relationship may actually be due to age – age is “confounding” our experimental design!

To control for this, we can make sure we also measure the age of each individual so that we can take into account the effects of age on literacy, as well. Another way we could control for age’s effect on literacy would be to fix the age of all participants. If everyone we study is the same age, then we have removed the possible effect of age on literacy.

Age is confounding my experimental design! We need to control for this
Age is confounding my experimental design! We need to control for this

In other experimental design paradigms, a control group may be appropriate. This is when you have a group of experimental subjects that are not manipulated. So if you were studying the effect of a drug on survival, you would have a group that received the drug (treatment) and a group that did not (control). This way, you can compare the effects of the drug in the treatment versus control group.

A control group is a group of subjects that do not receive the treatment, but still have their dependent variables measured
A control group is a group of subjects that do not receive the treatment, but still have their dependent variables measured

In these study designs, there are other strategies we can use to control for confounding effects. One, we can blind the subjects to their assigned treatment group. Sometimes, when a subject knows that they are in the treatment group (eg: receiving the experimental drug), they can feel better, not from the drug itself, but from knowing they are receiving treatment. This is known as the placebo effect. To combat this, often participants are blinded to the treatment group they are in; this is usually achieved by giving the control group a mock treatment (eg: given a sugar pill they are told is the drug). In this way, if the placebo effect is causing a problem with your experiment, both groups should experience it equally.

Blinding your study means that your subjects don’t know what group they belong to - all participants receive a treatment
Blinding your study means that your subjects don’t know what group they belong to - all participants receive a “treatment”

And this strategy is at the heart of many of these studies; spreading any possible confounding effects equally across the groups being compared. For example, if you think age is a possible confounding effect, making sure that both groups have similar ages and age ranges will help to mitigate any effect age may be having on your dependent variable - the effect of age is equal between your two groups.

This “balancing” of confounders is often achieved by randomization. Generally, we don’t know what will be a confounder beforehand; to help lessen the risk of accidentally biasing one group to be enriched for a confounder, you can randomly assign individuals to each of your groups. This means that any potential confounding variables should be distributed between each group roughly equally, to help eliminate/reduce systematic errors.

Randomizing subjects to either the control or treatment group is a great strategy to reduce confounders’ effects
Randomizing subjects to either the control or treatment group is a great strategy to reduce confounders’ effects

There is one final concept of experimental design that we need to cover in this lesson, and that is replication. Replication is pretty much what it sounds like, repeating an experiment with different experimental subjects. A single experiment’s results may have occured by chance; a confounder was unevenly distributed across your groups, there was a systematic error in the data collection, there were some outliers, etc. However, if you can repeat the experiment and collect a whole new set of data and still come to the same conclusion, your study is much stronger. Also at the heart of replication is that it allows you to measure the variability of your data more accurately, which allows you to better assess whether any differences you see in your data are significant.

Replication studies are a great way to bolster your experimental results and get measures of variability in your data
Replication studies are a great way to bolster your experimental results and get measures of variability in your data

Sharing data
Once you’ve collected and analysed your data, one of the next steps of being a good citizen scientist is to share your data and code for analysis. Now that you have a GitHub account and we’ve shown you how to keep your version controlled data and analyses on GitHub, this is a great place to share your code!

In fact, hosted on GitHub, our group, the Leek group, has developed a guide that has great advice for how to best share data!

Beware p-hacking!
One of the many things often reported in experiments is a value called the p-value. This is a value that tells you the probability that the results of your experiment were observed by chance. This is a very important concept in statistics that we won’t be covering in depth here, if you want to know more, check out this video explaining more about p-values.

What you need to look out for is when you manipulate p-values towards your own end. Often, when your p-value is less than 0.05 (in other words, there is a 5 percent chance that the differences you saw were observed by chance), a result is considered significant. But if you do 20 tests, by chance, you would expect one of the twenty (5%) to be significant. In the age of big data, testing twenty hypotheses is a very easy proposition. And this is where the term p-hacking comes from: This is when you exhaustively search a data set to find patterns and correlations that appear statistically significant by virtue of the sheer number of tests you have performed. These spurious correlations can be reported as significant and if you perform enough tests, you can find a data set and analysis that will show you what you wanted to see.

Check out this FiveThirtyEight activity where you can manipulate and filter data and perform a series of tests such that you can get the data to find whatever relationship you want!

XKCD mocks this concept in a comic testing the link between jelly beans and acne - clearly there is no link there, but if you test enough jelly bean colours, eventually, one of them will be correlated with acne at p-value < 0.05!

Summary
In this lesson we covered what experimental design is and why good experimental design matters. We then looked in depth to the principles of experimental design and defined some of the common terms you need to consider when designing an experiment. Next, we detoured a bit to see how you should share your data and code for analysis. And finally, we looked at the dangers of p-hacking and manipulating data to achieve significance.

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

código pra fazer um resumo dos dados:
summary ()

código para extrair somente casas, ou qualquer outra varíavel, específica:
nome_do_data_frame[Variavel %in% c("código da casa")]

sites com dados:
https://data.gov./
kaggle.com

There are 5 core activities of data analysis:
1. Stating and refining the question
2. Exploring the data
3. Building formal statistical models
4. Interpreting the results
5. Communicating the results

1. Descriptive
2. Exploratory
3. Inferential
4. Predictive
5. Causal
6. Mechanistic
And the type of question you are asking directly informs
how you interpret your results.
A descriptive question is one that seeks to summarize a characteristic of a set of data. Examples include determining
the proportion of males, the mean number of servings of
fresh fruits and vegetables per day, or the frequency of
viral illnesses in a set of data collected from a group of
individuals. There is no interpretation of the result itself as
the result is a fact, an attribute of the set of data that you are
working with.
An exploratory question is one in which you analyze the
data to see if there are patterns, trends, or relationships between variables. These types of analyses are also called “hypothesis-generating” analyses because rather than testing
a hypothesis as would be done with an inferential, causal,
or mechanistic question, you are looking for patterns that
would support proposing a hypothesis. If you had a general
thought that diet was linked somehow to viral illnesses, you
might explore this idea by examining relationships between
a range of dietary factors and viral illnesses. You find in
your exploratory analysis that individuals who ate a diet
high in certain foods had fewer viral illnesses than those
whose diet was not enriched for these foods, so you propose
the hypothesis that among adults, eating at least 5 servings
a day of fresh fruit and vegetables is associated with fewer
viral illnesses per year.

An inferential question would be a restatement of this proposed hypothesis as a question and would be answered by
analyzing a different set of data, which in this example, is
a representative sample of adults in the US. By analyzing
this different set of data you are both determining if the
association you observed in your exploratory analysis holds
in a different sample and whether it holds in a sample that
is representative of the adult US population, which would
suggest that the association is applicable to all adults in the
US. In other words, you will be able to infer what is true, on
average, for the adult population in the US from the analysis
you perform on the representative sample.
A predictive question would be one where you ask what
types of people will eat a diet high in fresh fruits and
vegetables during the next year. In this type of question
you are less interested in what causes someone to eat a
certain diet, just what predicts whether someone will eat
this certain diet. For example, higher income may be one
of the final set of predictors, and you may not know (or
even care) why people with higher incomes are more likely
to eat a diet high in fresh fruits and vegetables, but what is
most important is that income is a factor that predicts this
behavior.
Although an inferential question might tell us that people
who eat a certain type of foods tend to have fewer viral
illnesses, the answer to this question does not tell us if
eating these foods causes a reduction in the number of viral
illnesses, which would be the case for a causal question. A
causal question asks about whether changing one factor
will change another factor, on average, in a population.
Sometimes the underlying design of the data collection, by
default, allows for the question that you ask to be causal. An
example of this would be data collected in the context of a
randomized trial, in which people were randomly assigned
to eat a diet high in fresh fruits and vegetables or one that
was low in fresh fruits and vegetables. In other instances,
even if your data are not from a randomized trial, you
can take an analytic approach designed to answer a causal
question.
Finally, none of the questions described so far will lead to
an answer that will tell us, if the diet does, indeed, cause a
reduction in the number of viral illnesses, how the diet leads
to a reduction in the number of viral illnesses. A question
that asks how a diet high in fresh fruits and vegetables leads
to a reduction in the number of viral illnesses would be a
mechanistic question.
There are a couple of additional points about the types of
questions that are important. First, by necessity, many data
analyses answer multiple types of questions. For example,
if a data analysis aims to answer an inferential question, descriptive and exploratory questions must also be answered
during the process of answering the inferential question. To
continue our example of diet and viral illnesses, you would
not jump straight to a statistical model of the relationship
between a diet high in fresh fruits and vegetables and the
number of viral illnesses without having determined the
frequency of this type of diet and viral illnesses and their
relationship to one another in this sample. A second point
is that the type of question you ask is determined in part
by the data available to you (unless you plan to conduct a
study and collect the data needed to do the analysis). For
example, you may want to ask a causal question about diet
and viral illnesses to know whether eating a diet high in
fresh fruits and vegetables causes a decrease in the number
of viral illnesses, and the best type of data to answer this
causal question is one in which people’s diets change from
one that is high in fresh fruits and vegetables to one that
is not, or vice versa. If this type of data set does not exist,
then the best you may be able to do is either apply causal
analysis methods to observational data or instead answer
an inferential question about diet and viral illnesses.

princípios da análise exploratória principalmente com gráficos:
mostre comparações
mostre causalidade, mecânica, e explicação
mostre dados multivariados
integra vários modelos de evidência
descreva e documente as evidências
conteúdo é rei

gráficos na análise exploratória servem para:
entender as propriedades dos dados
encontrar padrões
sugerir estratégias de modelagem dos dados
depurar (melhorar) uma análise
comunicar resultados

características doa gráficos para análise exploratória:
feitos rapidamente
feitos em grande quantidade
para entendimento particular/pessoal
as preocupações estéticas ficam pra depois

para uma dimensão/variável:
sumário dos dados
boxplots
histogramas
gráficos de densidade
gráficos de barra

sumário:
valor mínimo
máximo
primeiro quartil
média
mediana
terceiro quartil

código:
summary()

boxplot()
abline(variável = 12) ## o valor "aceitável" de algum parâmetro

hist()
rug() ##detalhe sob o histograma para as medidas individuais

hist(variável, breaks = 100) ##diminuir a largura das barras do histograma
abline(variável = 12) ## o valor "aceitável" de algum parâmetro

barplot()

## para duas dimensões/variáveis:
gráficos de dispersão
multiple/overlayed 1-D gráficos (Lattice/ggplot2) por exemplo vários boxplots, gráficos de barras, dispersão
gráficos de dispersão suaves

código:
with(pollution, plot(latitude, pm25, col=region))
abline(h = 12, lwd = 2, lty = 2)

## mais de 2 dimensões:
multiple/overlayed 2-D gráficos; coplots
usar cores, tamanhos e formas para incluir mais dimensões

clusterização hierarquica para muitas variáveis
o quão próximos os grupos estão?
como agrupamos as coisas?
como visualizamos os grupos?
como interpretamos o agrupamento?

dendograma para vizualizar o agrupamento

qual a distância? o que é perto?
distância euclidiana
similaridade de correlação (distância análoga ou correlação entre dois pontos)
distância binária ou distância de manhattan
para clusterizar em R primeiro calcula-se a distância de todos os pontos entre eles
no dendograma podemos enxergar grupos de cluster. no exemplo do trabalho infantil podemos ter cluster de estados ou cidades para uma análise entre elas. quais características são iguais entre as cidades que podem caracterizar motivos do porque o trabalho infantil acontece
também é possível calcular a distância entre os "centros de massa" de cada cluster

também para muitas variáveis:
k-means clusterização - definição anterior de quantos grupos queremos (diferente da cluesterização hierarquica que definimos depois)
também é possível fazer mapas de calor das clusterizações

hierarquica é deterministica e k-means não (pelo fato de você poder escolher quantos clusters)

Análise de componentes principais (PCA) e decomposição de valor singular (SVD)
queremos encontrar um grupo de variáveis que não são correlacionadas pra poder explicar a variação do nosso conjunto de dados (ou seja, quais são as variáveis que explicam ao máximo os nossos números)
para isso fazer uma matriz com todos os dados, e um mapa de calor dessa matriz pra tentar agrupar algum grupo semelhante
não é possível usar essas técnicas com valores faltantes, temos que imputar dados
alguns outros modelos que fazem a mesma coisa: análise fatorial, análise independente de componentes, análise semântica latente
importante essa análise para perceber qual, ou quais, variáveis tem maior influência nos nossos números. talvez não seja necessário utilizar para diminuir as variáveis

##dicas do vídeo de análise
- se os dados são muito discrepantes, muitos outliers, olhar os dados na forma de logaritmos e também adicionar o número em todos os dados pra não ter que fazer log de zero
- olhar se os dados variam no ano, nos meses, nas semanas

##passos de uma análise
- definir a pergunta
- definir os dados a serem utilizados
- -obter os dados
- limpar os dados
- fazer a análise exploratória dos dados
- usar modelos de predição/modelagem
- interpretar os resultados
- desafira os dados/desconfiar dos dados/imaginar quais variáveis podem modificar os dados/refazer os cálculo usando essas novas provocações
- sintetizar e escrever os resultados
 